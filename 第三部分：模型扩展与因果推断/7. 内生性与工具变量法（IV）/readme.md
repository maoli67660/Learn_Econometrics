# 📖 第七章 · 内生性与工具变量法（Endogeneity & Instrumental Variables, IV）

---

## 🎯 学习目标

- 理解内生性是什么，为什么会发生
- 知道 OLS 在有内生性时是有偏的
- 掌握工具变量（Instrumental Variable, IV）的两个条件：相关性和外生性
- 学会两阶段最小二乘法（2SLS）的原理和步骤
- 理解 IV 回归与 OLS 的本质区别
- 能解释工具变量估计的因果含义（LATE）

---

## 🔹 7.1 什么是内生性？为什么是个问题？

我们考虑如下模型：

```math
Y_i = β₀ + β₁ X_i + ε_i
```

其中关键假设是：

```math
E[ε_i | X_i] = 0
```

若该假设被破坏（例如 X 与 ε 有相关性），我们称 X 是 **内生的**（endogenous）。

---

### ❌ 内生性的三大来源：

| 来源 | 含义 |
|------|------|
| 遗漏变量偏误 | 有重要变量没控制（如家庭背景） |
| 反向因果 | Y 也可能影响 X（如收入影响教育） |
| 测量误差 | X 被记录错误，尤其是自报数据 |

---

## 🔹 7.2 OLS 的问题：内生性导致有偏估计

OLS 的估计公式是：

```math
\hat{β}_{OLS} = \frac{Cov(X, Y)}{Var(X)}
```

若 \( Cov(X, ε) ≠ 0 \)，则：

```math
Cov(X, Y) = β Var(X) + Cov(X, ε)
```

→ 所以 \( \hat{β}_{OLS} \) 被污染了，不再是一致估计量。

---

## 🔹 7.3 工具变量（IV）方法：化解内生性的关键

### ✅ 什么是 IV？

> 工具变量 Z 是一个“推动 X，但不影响 Y”的外部变量

### ✅ 满足两个条件：

| 条件 | 含义 | 检验方式 |
|------|------|-----------|
| **相关性** | \( Cov(Z, X) ≠ 0 \) | 第一步回归的 F 值应 > 10 |
| **外生性** | \( Cov(Z, ε) = 0 \) | 理论判断 + Hansen 检验 |

---

### 🧪 举例：教育 → 收入（受家庭背景影响）

OLS 模型：

```math
收入 = β₀ + β₁ × 教育 + ε
```

教育受到家庭背景（家庭收入、父母职业）影响 ⇒ 内生性

---

### ✅ 工具变量选择：是否出生在教育改革后

- 出生在政策之后的人受教育更多（相关性 ✅）
- 政策和收入没有直接关系（外生性 ✅）

---

## 🔹 7.4 Two-Stage Least Squares（两阶段最小二乘法）

### 📍 第一步：用 Z 预测 X（解释变量）

```math
教育 = π₀ + π₁ × 政策 + v
```

→ 得到预测值 \( \hat{教育} \)

---

### 📍 第二步：用预测的 \( \hat{教育} \) 预测 Y（结果变量）

```math
收入 = β₀ + β₁ × \hat{教育} + u
```

→ 此时 \( \hat{教育} \) 不再与 ε 相关 ⇒ 估计 β₁ 是一致的

---

## 🔹 7.5 Python 示例：完整 2SLS 操作

```python
import pandas as pd
import numpy as np
import statsmodels.api as sm
from linearmodels.iv import IV2SLS

# 模拟数据
np.random.seed(0)
n = 500
policy = np.random.binomial(1, 0.5, n)
education = 8 + 2 * policy + np.random.normal(0, 1, n)
family_ability = np.random.normal(0, 1, n)
income = 2000 + 500 * education + 1000 * family_ability + np.random.normal(0, 1000, n)

df = pd.DataFrame({
    "income": income,
    "education": education,
    "policy": policy
})

# 一阶段：教育 ~ 政策
first_stage = sm.OLS(df['education'], sm.add_constant(df['policy'])).fit()
print(first_stage.summary())

# 二阶段：2SLS
iv_model = IV2SLS.from_formula("income ~ 1 + [education ~ policy]", df).fit()
print(iv_model.summary)
```

---

## 🔹 7.6 工具变量回归的哲学解释：为什么“粗”的预测也有价值？

### ✅ 你的直觉问题：

> “每个人教育年限都不一样，为什么只用政策变量（0/1）来预测？岂不是只知道两组人平均教育？”

是的，这种预测很粗。但：

---

### ✅ 工具变量估计的意义在于：

> **我们不是想预测教育的全部差异，而是只关注“由政策推动的教育差异”对收入的影响**

这就是著名的：

### 📌 LATE：局部平均处理效应（Local Average Treatment Effect）

- 只对**被工具变量“推了一把”**的人有效
- 比如：那些因为教育改革多上了两年学的人

---

### 🧠 总结 IV 的逻辑：

| 估计方式 | 使用的数据变异 | 是否可能有偏 | 能否解释因果 |
|-----------|------------------|---------------|----------------|
| OLS       | 所有教育变异       | ✅ 有偏         | ❌ 不可靠 |
| IV        | 只用政策导致的教育变异 | ❌ 无偏         | ✅ 因果解释有效 |

---

## 📝 小节总结（Summary）

| 内容 | 要点 |
|------|------|
| 内生性 | X 与误差项 ε 有相关性 |
| 工具变量法 | 用外生变量替代被污染的解释变量 |
| IV 条件 | 必须相关（推动 X），且外生（不影响 Y） |
| 2SLS | 第一步预测 X，第二步解释 Y |
| LATE | 工具变量估计的是“局部”因果效应 |
| 弱工具变量 | 会导致更糟的偏误，需避免（F > 10） |

---

## 📦 Takeaway 知识点携带包

- IV ≠ 更好的预测，而是更可靠的因果解释
- 工具变量估计的是“干净的变异”
- 工具变量估计的是 LATE，不是全体平均效应
- IV 比 OLS 更依赖理论合理性与经济直觉

---

📌 第八章预告：我们将进入时间序列回归，学习自回归、滞后项、单位根检验等核心工具，为宏观分析做准备！

